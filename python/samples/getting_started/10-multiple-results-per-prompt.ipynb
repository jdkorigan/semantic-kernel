{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68e1c158",
   "metadata": {},
   "source": [
    "# Multiple Results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb81bacd",
   "metadata": {},
   "source": [
    "In this notebook we show how you can in a single request, have the LLM model return multiple results per prompt. This is useful for running experiments where you want to evaluate the robustness of your prompt and the parameters of your config against a particular large language model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7120635",
   "metadata": {},
   "source": [
    "Import Semantic Kernel SDK from pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a77bdf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantic-kernel in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (1.34.0)\n",
      "Requirement already satisfied: azure-ai-projects>=1.0.0b11 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (1.0.0b11)\n",
      "Requirement already satisfied: azure-ai-agents>=1.1.0b1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (1.1.0b2)\n",
      "Requirement already satisfied: aiohttp~=3.8 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (3.12.13)\n",
      "Requirement already satisfied: cloudevents~=1.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (1.12.0)\n",
      "Requirement already satisfied: pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (2.11.7)\n",
      "Requirement already satisfied: pydantic-settings~=2.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: defusedxml~=0.7 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: azure-identity>=1.13 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (1.23.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (2.3.1)\n",
      "Requirement already satisfied: openai>=1.67 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (1.91.0)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (0.19.5)\n",
      "Requirement already satisfied: websockets<16,>=13 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (15.0.1)\n",
      "Requirement already satisfied: aiortc>=1.9.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (1.13.0)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (1.34.1)\n",
      "Requirement already satisfied: prance<25.4.9,>=23.6.21 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (25.4.8.0)\n",
      "Requirement already satisfied: pybars4~=0.9 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (0.9.13)\n",
      "Requirement already satisfied: jinja2~=3.1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (3.1.6)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (1.6.0)\n",
      "Requirement already satisfied: scipy>=1.15.1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (1.16.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (6.31.1)\n",
      "Requirement already satisfied: typing-extensions>=4.13 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from semantic-kernel) (4.14.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (6.5.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.20.1)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from cloudevents~=1.0->semantic-kernel) (2.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from deprecation<3.0,>=2.0->cloudevents~=1.0->semantic-kernel) (25.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from jinja2~=3.1->semantic-kernel) (3.0.2)\n",
      "Requirement already satisfied: isodate in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.24.0)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.3.4)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.7.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.6.3)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: parse in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (1.20.2)\n",
      "Requirement already satisfied: werkzeug<3.1.2 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (3.1.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.25.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (6.0.2)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (0.4.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (2.32.4)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel) (1.11.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from opentelemetry-api~=1.24->semantic-kernel) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from opentelemetry-sdk~=1.24->semantic-kernel) (0.55b1)\n",
      "Requirement already satisfied: chardet>=5.2 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from prance<25.4.9,>=23.6.21->semantic-kernel) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.18.10 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from prance<25.4.9,>=23.6.21->semantic-kernel) (0.18.14)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from pybars4~=0.9->semantic-kernel) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from pydantic-settings~=2.0->semantic-kernel) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (2025.6.15)\n",
      "Requirement already satisfied: aioice<1.0.0,>=0.10.1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (0.10.1)\n",
      "Requirement already satisfied: av<15.0.0,>=14.0.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (14.4.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=44.0.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (45.0.4)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (1.7.1)\n",
      "Requirement already satisfied: pyee>=13.0.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (13.0.0)\n",
      "Requirement already satisfied: pylibsrtp>=0.10.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (0.12.0)\n",
      "Requirement already satisfied: pyopenssl>=25.0.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (25.1.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel) (2.7.0)\n",
      "Requirement already satisfied: ifaddr>=0.2.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel) (0.2.0)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from azure-ai-agents>=1.1.0b1->semantic-kernel) (1.34.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.15.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from azure-ai-projects>=1.0.0b11->semantic-kernel) (12.25.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from azure-core>=1.30.0->azure-ai-agents>=1.1.0b1->semantic-kernel) (1.17.0)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from azure-identity>=1.13->semantic-kernel) (1.32.3)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from azure-identity>=1.13->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from cffi>=1.0.0->aiortc>=1.9.0->semantic-kernel) (2.22)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity>=1.13->semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openai>=1.67->semantic-kernel) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openai>=1.67->semantic-kernel) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openai>=1.67->semantic-kernel) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openai>=1.67->semantic-kernel) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openai>=1.67->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from openai>=1.67->semantic-kernel) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.67->semantic-kernel) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.67->semantic-kernel) (0.16.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from ruamel.yaml>=0.18.10->prance<25.4.9,>=23.6.21->semantic-kernel) (0.2.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\jerom\\onedrive\\ai-a-semantic-kernel-v1\\.venv\\lib\\site-packages (from tqdm>4->openai>=1.67->semantic-kernel) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.34.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: if using a virtual environment, do not run this cell\n",
    "%pip install -U semantic-kernel\n",
    "from semantic_kernel import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad09f90",
   "metadata": {},
   "source": [
    "Initial configuration for the notebook to run properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cff141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure paths are correct for the imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "\n",
    "sys.path.append(grandparent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d76e3d",
   "metadata": {},
   "source": [
    "### Configuring the Kernel\n",
    "\n",
    "Let's get started with the necessary configuration to run Semantic Kernel. For Notebooks, we require a `.env` file with the proper settings for the model you use. Create a new file named `.env` and place it in this directory. Copy the contents of the `.env.example` file from this directory and paste it into the `.env` file that you just created.\n",
    "\n",
    "**NOTE: Please make sure to include `GLOBAL_LLM_SERVICE` set to either OpenAI, AzureOpenAI, or HuggingFace in your .env file. If this setting is not included, the Service will default to AzureOpenAI.**\n",
    "\n",
    "#### Option 1: using OpenAI\n",
    "\n",
    "Add your [OpenAI Key](https://openai.com/product/) key to your `.env` file (org Id only if you have multiple orgs):\n",
    "\n",
    "```\n",
    "GLOBAL_LLM_SERVICE=\"OpenAI\"\n",
    "OPENAI_API_KEY=\"sk-...\"\n",
    "OPENAI_ORG_ID=\"\"\n",
    "OPENAI_CHAT_MODEL_ID=\"\"\n",
    "OPENAI_TEXT_MODEL_ID=\"\"\n",
    "OPENAI_EMBEDDING_MODEL_ID=\"\"\n",
    "```\n",
    "The names should match the names used in the `.env` file, as shown above.\n",
    "\n",
    "#### Option 2: using Azure OpenAI\n",
    "\n",
    "Add your [Azure Open AI Service key](https://learn.microsoft.com/azure/cognitive-services/openai/quickstart?pivots=programming-language-studio) settings to the `.env` file in the same folder:\n",
    "\n",
    "```\n",
    "GLOBAL_LLM_SERVICE=\"AzureOpenAI\"\n",
    "AZURE_OPENAI_API_KEY=\"...\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://...\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_TEXT_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_API_VERSION=\"...\"\n",
    "```\n",
    "The names should match the names used in the `.env` file, as shown above.\n",
    "\n",
    "For more advanced configuration, please follow the steps outlined in the [setup guide](./CONFIGURING_THE_KERNEL.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c2e146",
   "metadata": {},
   "source": [
    "We will load our settings and get the LLM service to use for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f924e1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using service type: Service.AzureOpenAI\n"
     ]
    }
   ],
   "source": [
    "from services import Service\n",
    "\n",
    "from samples.service_settings import ServiceSettings\n",
    "\n",
    "service_settings = ServiceSettings()\n",
    "\n",
    "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
    "selectedService = (\n",
    "    Service.AzureOpenAI\n",
    "    if service_settings.global_llm_service is None\n",
    "    else Service(service_settings.global_llm_service.lower())\n",
    ")\n",
    "print(f\"Using service type: {selectedService}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8ddffc1",
   "metadata": {},
   "source": [
    "First, we will set up the text and chat services we will be submitting prompts to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f8dcbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureChatPromptExecutionSettings,  # noqa: F401\n",
    "    AzureTextCompletion,\n",
    "    OpenAIChatCompletion,\n",
    "    OpenAIChatPromptExecutionSettings,  # noqa: F401\n",
    "    OpenAITextCompletion,\n",
    "    OpenAITextPromptExecutionSettings,  # noqa: F401\n",
    ")\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "# Configure Azure LLM service\n",
    "service_id = None\n",
    "if selectedService == Service.OpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    oai_chat_service = OpenAIChatCompletion(\n",
    "        service_id=\"oai_chat\",\n",
    "    )\n",
    "    oai_text_service = OpenAITextCompletion(\n",
    "        service_id=\"oai_text\",\n",
    "    )\n",
    "elif selectedService == Service.AzureOpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    aoai_chat_service = AzureChatCompletion(\n",
    "        service_id=\"aoai_chat\",\n",
    "    )\n",
    "    aoai_text_service = AzureTextCompletion(\n",
    "        service_id=\"aoai_text\",\n",
    "    )\n",
    "\n",
    "# Configure Hugging Face service\n",
    "if selectedService == Service.HuggingFace:\n",
    "    from semantic_kernel.connectors.ai.hugging_face import (  # noqa: F401\n",
    "        HuggingFacePromptExecutionSettings,\n",
    "        HuggingFaceTextCompletion,\n",
    "    )\n",
    "\n",
    "    hf_text_service = HuggingFaceTextCompletion(service_id=\"hf_text\", ai_model_id=\"distilgpt2\", task=\"text-generation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50561d82",
   "metadata": {},
   "source": [
    "Next, we'll set up the completion request settings for text completion services.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "628c843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_text_prompt_execution_settings = OpenAITextPromptExecutionSettings(\n",
    "    service=\"oai_text\",\n",
    "    extension_data={\n",
    "        \"max_tokens\": 80,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0.5,\n",
    "        \"presence_penalty\": 0.5,\n",
    "        \"number_of_responses\": 3,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "857a9c89",
   "metadata": {},
   "source": [
    "## Multiple Open AI Text Completions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2979db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selectedService == Service.OpenAI:\n",
    "    prompt = \"What is the purpose of a rubber duck?\"\n",
    "\n",
    "    results = await oai_text_service.get_text_contents(prompt=prompt, settings=oai_text_prompt_execution_settings)\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Result {i + 1}: {result}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4288d09f",
   "metadata": {},
   "source": [
    "## Multiple Azure Open AI Text Completions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5319f14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1: \n",
      "\n",
      "1. Online Research and Learning Development\n",
      "2. Organization for Research and Leadership Development\n",
      "3. Operational Risk and Loss Database\n",
      "4. Olympic Results and Legacy Database\n",
      "5. Open Resource Library for Development\n",
      "6. Order of the Royal Dragon \n",
      "7. Online Retailing and Distribution \n",
      "8. Office of Refugee Resettlement and Development \n",
      "9. Outer Ring Road Development \n",
      "10. Organic Recycling\n",
      "Result 2: \n",
      "\n",
      "1. Organization for the Research and Development of Languages\n",
      "2. Online Resources and Learning Database\n",
      "3. Office of Regulatory and Legislative Affairs\n",
      "4. Open Research and Learning Database\n",
      "5. Operational Research and Logistics Division\n",
      "6. Oceanic and Remote Landscapes Division\n",
      "7. Online Retailers and Distributors \n",
      "8. Oil Refinery Logistics Department\n",
      "9. Order, Rules, Laws\n",
      "Result 3: \n",
      "\n",
      "1. Online Research and Learning Database\n",
      "2. Organization of Regional and Local Development\n",
      "3. Operational Readiness and Logistics Division\n",
      "4. Office for Research and Liaison to the Disabled\n",
      "5. Open Resource Library for Development\n",
      "6. Order of the Royal Dragon\n",
      "7. Overseas Relief and Development\n",
      "8. On-demand Real-time Data\n",
      "9. Object-Oriented Requirements Definition\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if selectedService == Service.AzureOpenAI:\n",
    "    prompt = \"provide me a list of possible meanings for the acronym 'ORLD'\"\n",
    "\n",
    "    results = await aoai_text_service.get_text_contents(prompt=prompt, settings=oai_text_prompt_execution_settings)\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Result {i + 1}: {result}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb548f9c",
   "metadata": {},
   "source": [
    "## Multiple Hugging Face Text Completions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a148709",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selectedService == Service.HuggingFace:\n",
    "    hf_prompt_execution_settings = HuggingFacePromptExecutionSettings(\n",
    "        service_id=\"hf_text\",\n",
    "        extension_data={\"max_new_tokens\": 80, \"temperature\": 0.7, \"top_p\": 1, \"num_return_sequences\": 3},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9525e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selectedService == Service.HuggingFace:\n",
    "    prompt = \"The purpose of a rubber duck is\"\n",
    "\n",
    "    results = await hf_text_service.get_text_contents(prompt=prompt, settings=hf_prompt_execution_settings)\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Result {i + 1}: {result}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da632e12",
   "metadata": {},
   "source": [
    "Here, we're setting up the settings for Chat completions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5f11e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_chat_prompt_execution_settings = OpenAIChatPromptExecutionSettings(\n",
    "    service_id=\"oai_chat\",\n",
    "    max_tokens=80,\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0.5,\n",
    "    number_of_responses=3,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6bf238e",
   "metadata": {},
   "source": [
    "## Multiple OpenAI Chat Completions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dabc6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "if selectedService == Service.OpenAI:\n",
    "    chat = ChatHistory()\n",
    "    chat.add_user_message(\n",
    "        \"It's a beautiful day outside, birds are singing, flowers are blooming. On days like these, kids like you...\"\n",
    "    )\n",
    "    results = await oai_chat_service.get_chat_message_contents(\n",
    "        chat_history=chat, settings=oai_chat_prompt_execution_settings\n",
    "    )\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Result {i + 1}: {result!s}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdb8f740",
   "metadata": {},
   "source": [
    "## Multiple Azure OpenAI Chat Completions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66ba4767",
   "metadata": {},
   "outputs": [],
   "source": [
    "az_oai_prompt_execution_settings = AzureChatPromptExecutionSettings(\n",
    "    service_id=\"aoai_chat\",\n",
    "    max_tokens=80,\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0.5,\n",
    "    number_of_responses=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b74a64a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1: ...make myself a delicious, energizing breakfast! After that, I'll sit down with my favorite cup of coffee or tea and set some intentions for the day. I'll tackle my to-do list with focus and positivity, taking breaks when needed and staying present in each moment. Maybe I’ll even treat myself to something special—whether that’s a new book, a relaxing walk in nature, or catching up\n",
      "Result 2: ...make myself a delicious, healthy breakfast to kickstart the day! After that, I'll take some time to focus on my goals—whether that's journaling, planning out my tasks, or diving into something creative or productive. \n",
      "\n",
      "Maybe I’ll tackle that project I've been meaning to start or spend some time learning something new. And in the afternoon, I could meet up with a friend for coffee or\n",
      "Result 3: ...treat myself to a hearty, nourishing breakfast! After that, I'll dive into my goals for the day with energy and focus. Whether it's tackling a project I've been meaning to finish, exploring a new hobby, or connecting with loved ones, tomorrow is all about positivity and progress.  \n",
      "\n",
      "I’ll make sure to stay present, appreciate the little things, and remind myself how capable I am of creating\n"
     ]
    }
   ],
   "source": [
    "if selectedService == Service.AzureOpenAI:\n",
    "    content = (\n",
    "        \"Tomorrow is going to be a great day, I can feel it. I'm going to wake up early, go for a run, and then...\"\n",
    "    )\n",
    "    chat = ChatHistory()\n",
    "    chat.add_user_message(content)\n",
    "    results = await aoai_chat_service.get_chat_message_contents(\n",
    "        chat_history=chat, settings=az_oai_prompt_execution_settings\n",
    "    )\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Result {i + 1}: {result!s}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98c8191d",
   "metadata": {},
   "source": [
    "## Streaming Multiple Results\n",
    "\n",
    "Here is an example pattern if you want to stream your multiple results. Note that this is not supported for Hugging Face text completions at this time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26a37702",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selectedService == Service.OpenAI:\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    from IPython.display import clear_output\n",
    "\n",
    "    # Determine the clear command based on OS\n",
    "    clear_command = \"cls\" if os.name == \"nt\" else \"clear\"\n",
    "\n",
    "    chat = ChatHistory()\n",
    "    chat.add_user_message(\"what is the purpose of a rubber duck?\")\n",
    "\n",
    "    stream = oai_chat_service.get_streaming_chat_message_contents(\n",
    "        chat_history=chat, settings=oai_chat_prompt_execution_settings\n",
    "    )\n",
    "    number_of_responses = oai_chat_prompt_execution_settings.number_of_responses\n",
    "    texts = [\"\"] * number_of_responses\n",
    "\n",
    "    last_clear_time = time.time()\n",
    "    clear_interval = 0.5  # seconds\n",
    "\n",
    "    # Note: there are some quirks with displaying the output, which sometimes flashes and disappears.\n",
    "    # This could be influenced by a few factors specific to Jupyter notebooks and asynchronous processing.\n",
    "    # The following code attempts to buffer the results to avoid the output flashing on/off the screen.\n",
    "\n",
    "    async for results in stream:\n",
    "        current_time = time.time()\n",
    "\n",
    "        # Update texts with new results\n",
    "        for result in results:\n",
    "            texts[result.choice_index] += str(result)\n",
    "\n",
    "        # Clear and display output at intervals\n",
    "        if current_time - last_clear_time > clear_interval:\n",
    "            clear_output(wait=True)\n",
    "            for idx, text in enumerate(texts):\n",
    "                print(f\"Result {idx + 1}: {text}\")\n",
    "            last_clear_time = current_time\n",
    "\n",
    "    print(\"----------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
